{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1603261303844",
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "398dc28c06ad810e77de546bbdfa897a6ee0b83e59a5207339dda01a7843e01d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征处理与特征构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "from columns import base_columns\n",
    "li = []\n",
    "for col in base_info.columns:\n",
    "    ratio = base_info[base_info[col].isnull()].shape[0]/24865\n",
    "    num = len(base_info[col].value_counts())\n",
    "    dict_ = {'列名':col,'缺失量':ratio,'类别数':num,'字段类型':base_info[col].dtypes}\n",
    "    dict_['含义'] = base_columns.get(dict_['列名'])\n",
    "    li.append(dict_)\n",
    "pd.DataFrame(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非类别特征衍生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info['year'] = base_info['opfrom'].apply(lambda x:int(x.split('-')[0]))\n",
    "base_info['month'] = base_info['opfrom'].apply(lambda x:int(x.split('-')[1]))\n",
    "base_info['oprange'] = base_info['opto'].apply(lambda x:int(x[:4]) if not pd.isna(x) else x)\n",
    "base_info['oprange'] = base_info['oprange'] - base_info['year'].apply(int)\n",
    "base_info['oprange'] = base_info['oprange'].apply(lambda x:x if not pd.isna(x) else 999)\n",
    "base_info.drop(['opto','opfrom'],axis=1,inplace=True)\n",
    "base_info['reccap'] = base_info['reccap'].apply(lambda x:False if pd.isna(x) else True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from columns import base_columns\n",
    "li = []\n",
    "for col in category3_columns:\n",
    "    ratio = base_info[base_info[col].isnull()].shape[0]/24865\n",
    "    num = len(base_info[col].value_counts())\n",
    "    dict_ = {'列名':col,'缺失量':ratio,'类别数':num,'字段类型':base_info[col].dtypes}\n",
    "    dict_['含义'] = base_columns.get(dict_['列名'])\n",
    "    li.append(dict_)\n",
    "pd.DataFrame(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类别特征衍生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "category1_columns = ['state','regtype','compform','venind']#10个以下类别的\n",
    "category2_columns = ['oplocdistrict','industryphy','enttype']#10-30个类别的\n",
    "category3_columns = ['industryco','enttypeitem','opform','enttypeminu','enttypegb']#超过30个类别的\n",
    "category4_columns = ['dom','opscope','orgid','jobid','oploc']#有规律的特征\n",
    "category_columns = category1_columns + category2_columns + category3_columns + category4_columns\n",
    "\n",
    "for col in category_columns:\n",
    "    base_info[col] = base_info[col].apply(lambda x:str(x) if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base数据特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 规律变量特征衍生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info['dom_1'] = base_info['dom'].str[:1]#16\n",
    "base_info['dom_2'] = base_info['dom'].str[:16]#53\n",
    "base_info['dom_3'] = base_info['dom'].str[:32]#412\n",
    "base_info['dom_4'] = base_info['dom'].str[:48]#1792\n",
    "base_info.drop(['dom'],axis=1,inplace=True)\n",
    "\n",
    "base_info['orgid_1'] = base_info['orgid'].str[:4]#3\n",
    "base_info['orgid_2'] = base_info['orgid'].str[:7]#12\n",
    "base_info['orgid_3'] = base_info['orgid'].str[:12]#41\n",
    "\n",
    "base_info['jobid_1'] = base_info['jobid'].str[:2]#3\n",
    "base_info['jobid_2'] = base_info['jobid'].str[:10]#7\n",
    "base_info['jobid_3'] = base_info['jobid'].str[:14]#46\n",
    "\n",
    "base_info['oploc_1'] = base_info['oploc'].str[:1]#16\n",
    "base_info['oploc_2'] = base_info['oploc'].str[:2]#165\n",
    "base_info['oploc_3'] = base_info['oploc'].str[:16]#231\n",
    "base_info['oploc_4'] = base_info['oploc'].str[:32]#752\n",
    "base_info.drop(['oploc'],axis=1,inplace=True)\n",
    "category5_columns = ['dom_1','dom_2','dom_3','dom_4','orgid','orgid_1','orgid_2','orgid_3','jobid','jobid_1','jobid_2','jobid_3','oploc_1','oploc_2','oploc_3','oploc_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stpwrdpath = \"stop_words.txt\"\n",
    "stpwrd_dic = open(stpwrdpath, 'rb')\n",
    "stpwrd_content = stpwrd_dic.read()\n",
    "stpwrdlst = stpwrd_content.splitlines()\n",
    "stpwrd_dic.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "corpus = base_info['opscope'].apply(lambda x:' '.join(jieba.cut(x))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "cntVector = CountVectorizer(stop_words=stpwrdlst)\n",
    "cntTf = cntVector.fit_transform(corpus)\n",
    "lda = LatentDirichletAllocation(n_components=20,\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "docres = lda.fit_transform(cntTf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_feature = pd.DataFrame(docres)\n",
    "lda_feature.columns = ['lad_'+str(i) for i in range(1,21)]\n",
    "lda_feature['id'] = base_info['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info = base_info.merge(lda_feature,on=['id'],how='left')\n",
    "base_feature = base_info.drop(['opscope'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 少类别特征\n",
    "for col in category1_columns + category2_columns:\n",
    "    base_info[col] = base_info[col].astype('category')\n",
    "\n",
    "# 多类别特征\n",
    "def categorys_count_rank(data,col):\n",
    "    '''\n",
    "    针对类别较多的变量，按出现的次数对其进行编码\n",
    "    '''\n",
    "    category_dict = dict(data[col].value_counts().rank(method='dense'))\n",
    "    return data[col].replace(category_dict)\n",
    "for col in category2_columns + category3_columns + category5_columns:\n",
    "    base_info[col+'_count_rank'] = categorys_count_rank(base_info,col)\n",
    "\n",
    "\n",
    "def categorys_label_feature(data,col):\n",
    "    '''\n",
    "    针对类别较少的变量，进行特征衍生\n",
    "    特征1:在label=1的数据中，该变量所占比\n",
    "    特征2:该类别下，label=1的比例\n",
    "    '''\n",
    "    data1 = data[data['label']==1]\n",
    "    category_dict1, category_dict2 = {}, {}\n",
    "    for value in data[col].value_counts().index.tolist():\n",
    "        ratio1 = data1[data1[col]==value].shape[0]/data1.shape[0]\n",
    "        category_dict1[value] = ratio1\n",
    "        ratio2 = data[(data[col]==value)&(data['label']==1)].shape[0]/data[data[col]==value].shape[0]\n",
    "        category_dict2[value] = ratio2\n",
    "    return category_dict1,category_dict2\n",
    "\n",
    "for col in category2_columns + category3_columns + category5_columns:\n",
    "    category_dict1,category_dict2 = categorys_label_feature(base_info,col)\n",
    "    base_info[col+'_label_feature1'] = base_info[col].apply(lambda x:category_dict1.get(x,x))\n",
    "    base_info[col+'_label_feature2'] = base_info[col].apply(lambda x:category_dict2.get(x,x))\n",
    "\n",
    "base_info.drop(category3_columns + category5_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "X_train = train_data.drop(['id','label'],axis=1)\n",
    "y_train = train_data['label']\n",
    "X_test = test_data.drop(['id','label'],axis=1)\n",
    "lgb_train = lgb.Dataset(X_train,label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'learning_rate': 0.01, \n",
    "    'num_leaves': 50, \n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.8, \n",
    "    }\n",
    "cv_results = lgb.cv(params, lgb_train, \n",
    "                    num_boost_round=2000, \n",
    "                    nfold=5, \n",
    "                    shuffle=True, \n",
    "                    metrics='binary_logloss,auc',\n",
    "                    early_stopping_rounds=400, \n",
    "                    verbose_eval=50, \n",
    "                    categorical_feature=category1_columns + category2_columns,\n",
    "                    show_stdv=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best n_estimators:', len(cv_results['auc-mean']))\n",
    "print('best cv score:', cv_results['auc-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', \n",
    "    objective='binary', \n",
    "    metrics='binary_logloss,auc',\n",
    "    learning_rate=0.01, \n",
    "    bagging_fraction=0.8, \n",
    "    feature_fraction=0.8,\n",
    "    n_estimators=706,\n",
    "    njobs=2,\n",
    "    max_depth=6,\n",
    "    num_leaves=25\n",
    ")\n",
    "estimator.fit(X_train,y_train,categorical_feature=category1_columns + category2_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict_proba(X_test)\n",
    "result = pd.DataFrame()\n",
    "result['id'] = test_data['id']\n",
    "result['score'] = [i[1] for i in y_pred]\n",
    "result.to_csv('result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info = pd.read_csv('./train/base_info.csv')\n",
    "label = pd.read_csv('./train/entprise_info.csv')\n",
    "base_info = base_info.merge(label,on=['id'],how='left')\n",
    "drop_columns = ['parnum','exenum','ptbusscope','midpreindcode','protype','forreccap','forregcap','congro']#缺失值太多，直接舍弃\n",
    "base_info.drop(drop_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(24865, 34)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "base_columns = ['id':'企业唯一标识', 'oplocdistrict':'行政区划代码', 'industryphy':'行业类别代码', 'industryco':'行业细类代码', \n",
    "                'dom':'经营地址', #\n",
    "                'opscope':'经营范围', #LDA处理\n",
    "                'enttype':'企业类型', 'enttypeitem':'企业类型小类', #0.33\n",
    "                'opfrom':'经营期限起', 'opto':'经营期限止', #0.65缺失之填充“9999-12-31”\n",
    "                'state':'状态', 'orgid':'机构标识', 'jobid':'职位标识', 'adbusign':'是否广告经营', 'townsign':'是否城镇', 'regtype':'主题登记类型',\n",
    "                'empnum':'从业人数', #0.21\n",
    "                'compform':'组织形式', #0.57,缺失值作为第三类\n",
    "                'parnum':'合伙人数', #删除0.91,转化称bool变量\n",
    "                'exenum':'执行人数', #删除\n",
    "                'opform':'经营方式', #0.64#删除\n",
    "                'ptbusscope':'兼营范围', #1删除\n",
    "                'venind':'风险行业', #0.66\n",
    "                'enttypeminu':'企业类型细类', #0.71删除\n",
    "                'midpreindcode':'中西部优势产业代码', #1删除\n",
    "                'protype':'项目类型', #删除\n",
    "                'oploc':'经营场所', #删除\n",
    "                'regcap':'注册资本（金）', #0.01\n",
    "                'reccap':'实缴资本', #0.72,转化成是否为空\n",
    "                'forreccap':'实缴资本（外方）', #删除\n",
    "                'forregcap':'注册资本（外方）', #删除\n",
    "                'congro':'投资总额', #删除\n",
    "                'enttypegb':'企业（机构）类型'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#类别超多>100\n",
    "category1 = ['industryco',]\n",
    "#类别较多10-30\n",
    "category2 = ['enttypeitem','enttypeitem','enttypegb']\n",
    "#存在规律类别\n",
    "category3 = ['dom','opscope','orgid','jobid','oploc']\n",
    "#类别较少<10\n",
    "category4 = ['oplocdistrict','industryphy','enttype','state','adbusign','townsign','regtype','compform','venind']\n",
    "\n",
    "base_info['opfrom'] = base_info['opfrom'].str[:10]\n",
    "base_info['opto'] = base_info['opto'].str[:4].fillna('9999')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1100    14085\n9600     8193\n4500     2180\n2100      141\n1200       81\n2200       40\n3100       37\n3200       29\n9100       23\n5100       20\n6100       19\n4400        8\n5800        3\n3500        2\n6800        2\n3400        1\n5400        1\nName: enttype, dtype: int64"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "base_info['enttype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = base_feature[base_feature['label'].notnull()]\n",
    "test_data = base_feature[base_feature['label'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数1:n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'binary', \n",
    "    'learning_rate': 0.1, \n",
    "    'num_leaves': 50, \n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.8, \n",
    "    }\n",
    "cv_results = lgb.cv(params, lgb_train, \n",
    "                    num_boost_round=1000, \n",
    "                    nfold=5, \n",
    "                    shuffle=True, \n",
    "                    metrics='binary_logloss,auc',\n",
    "                    early_stopping_rounds=100, \n",
    "                    verbose_eval=50, \n",
    "                    categorical_feature=short_categorys,\n",
    "                    show_stdv=True, seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数2:max_depth,num_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', \n",
    "    objective='binary', \n",
    "    metrics='binary_logloss,auc',\n",
    "    learning_rate=0.1, \n",
    "    bagging_fraction=0.8, \n",
    "    feature_fraction=0.8,\n",
    "    n_estimators=98,\n",
    "    njobs=2\n",
    ")\n",
    "param_grid = {\n",
    "    'max_depth': [2,3,4],\n",
    "    'num_leaves':[10,15,20]\n",
    "}\n",
    "gbm = GridSearchCV(estimator,param_grid,cv=5)\n",
    "gbm.fit(X_train,y_train)\n",
    "gbm.best_params_,gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "e9f7b28ec10e04707ba878b89e6c2d362b107a817342f9c6    2\nf000950527a6feb6021414e7554476d0cf027e4d1dc3e864    1\nf000950527a6feb6cb47be6daff20d71af700226c9047ea7    1\ne9f7b28ec10e047036ecf3701c5e3d58d703c0b8192f1e68    1\nd8071a739aa75a3bf05a79bf7f26ecf8ad9b52d060b8faf2    1\ne9f7b28ec10e0470114e0094ac7afee09f69ba51f808d722    1\nf1c1045b13d18329d0913745443552947bcc4bbc3a2d1e2a    1\nf000950527a6feb638468abc79eda66fd48fc018b8b43229    1\ne9f7b28ec10e0470df8f4662efb233711b33c9c0809662ab    1\nf1c1045b13d18329d447d7013c1b322c46ac671936e88474    1\ned38190adf12fceb52155e51e3e6576fda26e707ac90c29e    1\ned38190adf12fceb56e6c30fb2c24feb8e5a75cb72530fd6    1\nda8691b210adb3f6aef7f82ff03bded18841fd7b1b405451    1\n59b38c56de3836835cdfe9f4e2d51d7450911703ecdbfcf7    1\nd8071a739aa75a3b4e60b4c2c41fb122d4a26f8680e3038e    1\n755db3b5c5f74eb409854d84d1a303b795fc3a2812568998    1\nbeb4aaaa89e0a0aeca97c467a612082a7c5722d9250d6557    1\n4a8fc4f3fb4d8a0fda7f2062186b69d2e35d4950f70dd02d    1\nd8071a739aa75a3bf0bd2aca4b6060d92ba5411ec06f460b    1\nf000950527a6feb640a5242a3e340c181e79852efce23a1b    1\ne9f7b28ec10e0470af4ef7382399ab8e0bbae2bf73c9640d    1\n516ab81418ed215d7d230675fb0cfe383f439a9eeba69028    1\nd8071a739aa75a3b68e498c2086f32f5edde9983317272ff    1\nbeb4aaaa89e0a0aee3dfc468b1a2b6baf8a36447c4dfd02b    1\nda8691b210adb3f6e963aaea6f91482504f22d025ac3e03c    1\n216bd2aaf4d07924bb4fe39079e40f440be88b1cab8ec8d3    1\nd8071a739aa75a3b4cb3e520dad0b06d3be6203e203f2cdb    1\n47645761dc56bb8c954dd5f8db6ae4ae596f1f26d971fc4a    1\nda8691b210adb3f6e1e31abe33c5938048ec2936e0e2a104    1\nf000950527a6feb6dcce511a4aa17f41478e688ab847c598    1\n                                                   ..\n47645761dc56bb8c91409fe0a8fc13a76ba300b0306379ff    1\nbeb4aaaa89e0a0aee7fbc0cce3b2ee4cbed23f6cedac87ee    1\n4a8fc4f3fb4d8a0fcf7dc72ff0d29f6b286bfd016ab0de83    1\nd8071a739aa75a3b5b3b71293eb9ff0bcb34b693bb5e4cc8    1\n82750f1b9d122350a3f080d8f2193a100bc7b08f10f7239b    1\nbeb4aaaa89e0a0ae18e8613cfa61f4fa9a8ef0cadbd0256b    1\n9c7fa510616a68304a00c253e0deb4fb874173e852dbf5e4    1\ne9f7b28ec10e04705db3a9c9208329e8abb6b4bc0a3889c6    1\ne9f7b28ec10e0470b1bc33e7210cd01453fc32b4c6332c8c    1\nf000950527a6feb67abcd75c9d3c24f04d625669e0cc1196    1\n516ab81418ed215d2b0c4448b46e380c78a50b60ff968ab5    1\nf000950527a6feb6e46a067be14e585ecf0696997d4511ed    1\nd8071a739aa75a3b33a23d366e25d2bf0357ece892065cf0    1\n59b38c56de383683b9443741fb266aad1267aced79039868    1\n516ab81418ed215d7ad1578a274613e94d8c34edf285fa1f    1\nda8691b210adb3f692095a71ef9a82bf27db963558d495fd    1\nbeb4aaaa89e0a0ae8abb935c1c3f8f5d6cffaeeaf9f56ca5    1\nf000950527a6feb61533d666ae2fe2b85bf9c0c7e41e86c1    1\nf000950527a6feb6d0ae3c822e70b70e24e54d3f5ff98078    1\nd8071a739aa75a3bcb71dedd2c79d64dae0141b2ba4625b7    1\nf000950527a6feb6370353e68872061579c52a2260a880b8    1\nf000950527a6feb6b96bb88b3427f97369e6ecec4e37ba24    1\n516ab81418ed215d727b03b91b0258073152ded73f78c9d8    1\n755db3b5c5f74eb4dcf57f301983beab4dfcdf1834e6f6eb    1\nf1c1045b13d183298e4ff52acb8ffa244a9b9a19da198a2a    1\nf000950527a6feb6dd9df9e2c043bdc398dda00c274a93ff    1\nf000950527a6feb6b4d4addbbf31cba1a02e0fbe901ec4fa    1\ne9f7b28ec10e047047ab077b3fb6ba8428763edf0ea49e7e    1\nf000950527a6feb67accfcc085371020b653c79fdf572fd2    1\nf000950527a6feb68f0971b16adb44646a5f04ffa9f2ca57    1\nName: id, Length: 10000, dtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "x['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}